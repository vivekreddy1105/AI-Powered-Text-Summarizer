

#  AI-Powered Text Summarizer

## **Objective**

This project implements an **AI-powered text summarizer** using transformer-based models. The application can summarize large texts into concise **3â€“5 sentence summaries** and supports **batch summarization**. It also includes **runtime warnings, truncation safeguards, and an interactive Gradio web interface**.

---

## **Features**

* âœ… Summarizes **long documents** (splitting into chunks when necessary).
* âœ… Ensures summaries are between **3â€“5 sentences**.
* âœ… Handles **batch summarization** (multiple articles separated by `---`).
* âœ… Includes **truncation safeguards** and **runtime warnings**.
* âœ… Interactive **Gradio interface** with tabs for single and batch input.
* âœ… Debug accordion showing runtime configuration and copyright.
* âœ… Integrated **ROUGE evaluation support** (if dependencies are installed).

---

## **Requirements**

### Python Version

* Python **3.8+**

### Install Dependencies

Create a virtual environment and install dependencies:

```bash
pip install torch transformers gradio evaluate
```

> âš ï¸ If ROUGE evaluation fails, install missing metrics:

```bash
pip install absl-py rouge-score
```

---

## **Usage**

### Run the application

```bash
python app.py
```

This launches a **Gradio web app** at `http://127.0.0.1:7860`.

---

### Web Interface

* **Single Tab**: Paste a long article or paper â†’ get a 3â€“5 sentence summary.
* **Batch Tab**: Paste multiple articles separated by `---` â†’ get separate summaries.

**Debug / Warnings Accordion**:

* Displays truncation and runtime warnings.
* Shows current token settings (`SAFE_MAX_INPUT_LEN`, `CHUNK_TOKEN_TARGET`, `CHUNK_OVERLAP`).
* Includes copyright and author links.

---

## **Implementation Details**

### Model

* Uses Hugging Faceâ€™s **facebook/bart-large-cnn** transformer for **abstractive summarization**.
* Loaded with `transformers.pipeline("summarization")`.
* Automatically uses **GPU if available**.

### Preprocessing

1. **Sentence Splitting** â†’ Ensure well-formed summaries.
2. **Chunking** â†’ Long documents split by tokens with overlap.
3. **Safe Truncation** â†’ Ensures inputs never exceed modelâ€™s safe max length.

### Summarization Logic

* For short texts â†’ summarize directly.
* For long texts â†’

  1. Split into chunks.
  2. Summarize each chunk.
  3. Fuse summaries and generate a final short summary.

### Batch Processing

* Multiple texts handled via `summarize_batch()` and `summarize_multi()`.
* Input documents must be separated by a line with `---`.

---

## **Optional: ROUGE Evaluation**

The code integrates Hugging Faceâ€™s `evaluate` library to load **ROUGE metrics** for measuring summary quality (requires `rouge-score` package).

Example:

```python
from evaluate import load
rouge = load("rouge")
results = rouge.compute(predictions=[summary], references=[reference])
```

---

## **Deliverables**

* **Code** (`app.py`): Implements the summarizer with Gradio UI.
* **requirements.txt**: Lists dependencies.
* **Documentation**: Explains setup, usage, and implementation.

---

## **Evaluation Criteria**

* âœ”ï¸ **Correct functionality**: Summaries constrained to 3â€“5 sentences.
* âœ”ï¸ **NLP model usage**: Transformer-based abstractive summarization.
* âœ”ï¸ **Batch support**: Multiple articles handled seamlessly.
* âœ”ï¸ **Code quality**: Modular, error-handled, GPU support.
* âœ”ï¸ **Documentation clarity**: Setup + usage explained.
* â­ Optional: Web interface, runtime warnings, ROUGE integration.

---

## **Author**

* **Â© Vivek Reddy**
* ğŸ”— [GitHub](https://github.com/vivekreddy1105)
* ğŸ”— [LinkedIn](https://linkedin.com/in/vivekreddy1105)

---

Do you want me to also generate a **`requirements.txt`** file for this project so you can drop it into your repo?
